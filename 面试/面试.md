# 面试

## 英文自我介绍

### **简单版英文自我介绍**

**Part 1: Greeting & Who You Are (开场与身份)**

> "Hello, my name is Huang Qiwen. I'm a backend engineer with over 4 years of experience. I love building efficient and scalable systems."

**中文解释**：

> “面试官你好，我叫黄奇文。我是一名有四年多经验的后端工程师。我热爱构建高效和可扩展的系统。”
> **背诵点**：简单开场，说出名字、身份和热情所在。

------

**Part 2: Education & Current Job (教育与当前工作)**

> "I have a master's degree in Computer Science. I currently work at Shanghai Biren Tech, where my main focus is on designing CI/CD systems and automated testing frameworks."

**中文解释**：

> “我拥有计算机科学硕士学位。目前我在上海壁仞科技工作，主要负责设计CI/CD系统和自动化测试框架。”
> **背诵点**：学历 + 公司 + 核心工作内容（CI/CD和测试框架）。

------

**Part 3: Key Project & Achievement (核心项目与成就)**

> "My key project was building a distributed testing system. We used Jenkins, Redis, and Python to make test runs 8 times faster. This work even led to a patent."

**中文解释**：

> “我的核心项目是搭建了一个分布式测试系统。我们使用了Jenkins、Redis和Python，让测试速度提升了8倍。这项工作还成功申请了一项专利。”
> **背诵点**：**项目**（分布式测试系统）+ **技术**（Jenkins, Redis, Python）+ **成果**（8倍提速，有专利）。这是你最硬的干货，一定要流利。

------

**Part 4: Technical Skills (技术技能)**

> "I'm good at programming in Go and Python. I also have experience with databases like MySQL and Redis, and DevOps tools like Docker and Jenkins."

**中文解释**：

> “我擅长使用Go和Python编程。我也有使用MySQL、Redis等数据库，以及Docker、Jenkins等DevOps工具的经验。”
> **背诵点**：**语言**（Go, Python）+ **数据库**（MySQL, Redis）+ **工具**（Docker, Jenkins）。覆盖了你技能点的核心。

------

**Part 5: Closing (结尾)**

> "I'm a team player and a quick learner. I'm really excited about this opportunity and believe I can contribute to your team. Thank you."

**中文解释**：

> “我具备团队合作精神，并且学习能力很快。我对这次机会感到非常兴奋，相信我能为您的团队做出贡献。谢谢。”
> **背诵点**：表达个人软技能（团队合作、学习能力）、热情和感谢。

------

### **完整串联版**

```

Hello, my name is Huang Qiwen. I'm a backend engineer with over 4 years of experience. I love building efficient and scalable systems.

I have a master's degree in Computer Science. I currently work at Shanghai Biren Tech, where my main focus is on designing CI/CD systems and automated testing frameworks.

My key project was building a distributed testing system. We used Jenkins, Redis, and Python to make test runs 8 times faster. This work even led to a patent.

I'm good at programming in Go and Python. I also have experience with databases like MySQL and Redis, and DevOps tools like Docker and Jenkins.

I'm a team player and a quick learner. I'm really excited about this opportunity and believe I can contribute to your team. Thank you
```



## Gin

### **一、基础概念题**

**1. Gin 框架是什么？它有什么核心优势？**

**参考回答：**
Gin 是一个用 Go 编写的高性能 HTTP Web 框架。它的核心优势在于：

- **性能极高**：得益于 Go 语言本身的性能以及 Gin 的轻量级设计，它的路由和中间件处理速度非常快。
- **内存占用少**：相比其他框架，Gin 的内存分配和消耗更少，非常适合构建高并发 API 服务。
- **强大的路由**：支持动态路由、路由分组，并且路由匹配算法效率很高。
- **中间件支持**：拥有丰富的中间件生态系统，可以方便地实现日志、认证、跨域等通用功能。开发者也可以轻松编写自定义中间件。
- **易于上手**：API 设计简洁明了，学习曲线平缓，文档友好。

**关联项目**：在我构建的测试用例管理平台中，正是看中了 Gin 的高性能和轻量级特性，能够快速响应前端的各种 API 请求，同时保持服务稳定和低资源消耗。

------

### **二、路由与参数**

**2. Gin 中的路由是如何工作的？路由分组有什么好处？**

**参考回答：**
Gin 的路由是基于 `httprouter` 的，它使用了一种压缩的 **前缀树（Radix Tree）** 数据结构来存储和匹配路由。这使得路由匹配非常快速，且支持带参数的动态路由（如 `/user/:id`）。

**路由分组** 的好处在于：

- **代码组织**：可以将同一前缀或具有相同中间件的路由组织在一起，使代码更清晰。
- **中间件复用**：可以为整个路由组统一添加中间件，比如为所有 `/api/v1/admin` 下的路由添加管理员权限校验中间件。

**关联项目示例**：在我的项目中，我大量使用了路由分组。例如：

go

```go
// 测试用例相关API组
testCaseGroup := r.Group("/api/v1/testcases")
testCaseGroup.Use(AuthMiddleware()) // 组内统一认证
{
    testCaseGroup.GET("", GetTestCases)    // GET /api/v1/testcases
    testCaseGroup.POST("", CreateTestCase) // POST /api/v1/testcases
    testCaseGroup.PUT("/:id", UpdateTestCase) // PUT /api/v1/testcases/123
}
```



这样，所有以 `/api/v1/testcases` 开头的路由都自动经过了身份验证，代码非常整洁。

------

### **三、中间件**

**3. 解释一下 Gin 中间件的执行流程？`next()` 函数的作用是什么？**

**参考回答：**
Gin 的中间件执行流程是一个 **链式调用**，类似于一个“洋葱模型”。

1. 当一个请求到达时，会依次经过所有注册的中间件。
2. 在每个中间件中，调用 `c.Next()` 会**暂停当前中间件**，并**跳转到后续的中间件和最终的路由处理函数**。
3. 当后续的所有处理都完成后，程序会**沿着原路返回**，继续执行 `c.Next()` 之后剩下的代码。

所以，一个中间件的完整执行是分两部分的：

- `c.Next()` 之前：在请求**到达**路由处理函数前执行（常用于权限验证、日志记录）。
- `c.Next()` 之后：在请求**离开**路由处理函数后执行（常用于记录响应时间、统一封装响应）。

**关联项目示例**：我写过一个日志中间件，它记录了请求处理的总耗时：

go

```go
func LoggingMiddleware(c *gin.Context) {
    start := time.Now() // 1. 请求到达时记录开始时间
    
    c.Next() // 2. 跳转到后续处理
    
    // 3. 请求处理完毕后，记录耗时
    duration := time.Since(start)
    log.Printf("Request %s %s handled in %v", c.Request.Method, c.Request.URL.Path, duration)
}
```



**4. 如何编写一个自定义中间件？你写过哪些？**

**参考回答**：
编写自定义中间件非常简单，它就是一个返回 `gin.HandlerFunc` 的函数。

**关联项目示例**：在我的测试平台中，我写过两个关键的中间件：

1. **JWT 认证中间件**：

   go

   ```go
   func AuthMiddleware() gin.HandlerFunc {
       return func(c *gin.Context) {
           token := c.GetHeader("Authorization")
           // 验证 token 逻辑...
           if tokenInvalid {
               c.AbortWithStatusJSON(401, gin.H{"error": "Unauthorized"})
               return // 验证失败，调用 Abort 终止后续执行
           }
           // 验证成功，将用户信息存入 Context，供后续处理函数使用
           c.Set("user", userInfo)
           c.Next()
       }
   }
   ```

   

2. **全局错误恢复中间件**：使用 `defer` 和 `recover()` 捕获 panic，防止服务因未处理的错误而崩溃，并返回 500 错误给客户端。

------

### **四、数据绑定与验证**

**5. Gin 中如何绑定请求数据（JSON/表单）？如何验证数据？**

**参考回答**：
Gin 提供了强大的数据绑定功能。

- **绑定JSON**：使用 `c.ShouldBindJSON(&obj)`
- **绑定表单/查询参数**：使用 `c.ShouldBind(&obj)` 或 `c.ShouldBindQuery(&obj)`

对于数据验证，Gin 推荐使用 **`go-playground/validator`** 库。我们可以在结构体字段上使用 `binding` 标签来定义验证规则。

**关联项目示例**：在创建测试用例的 API 中，我这样定义和验证输入：

go

```go
type CreateTestCaseRequest struct {
    Name        string `json:"name" binding:"required,min=1"`        // 必填，最小长度1
    Description string `json:"description"` 
    ScriptPath  string `json:"script_path" binding:"required"`       // 必填
    Priority    int    `json:"priority" binding:"oneof=1 2 3"`       // 只能是1,2,3中的一个
}

func CreateTestCase(c *gin.Context) {
    var input CreateTestCaseRequest
    if err := c.ShouldBindJSON(&input); err != nil {
        // 绑定或验证失败，返回详细的错误信息
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }
    // ... 后续业务逻辑
}
```



------

### **五、高级特性与最佳实践**

**6. 如何优雅地关闭 Gin 服务？**

**参考回答**：
优雅关闭的目的是让服务在退出前，能够处理完已接收的请求，并释放资源。我们可以使用 Go 1.8 引入的 `http.Server` 的 `Shutdown` 方法，并监听操作系统信号。

go

```go
srv := &http.Server{
    Addr:    ":8080",
    Handler: router, // 你的 Gin 引擎
}

go func() {
    // 在协程中启动服务
    if err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {
        log.Fatalf("listen: %s\n", err)
    }
}()

// 等待中断信号
quit := make(chan os.Signal, 1)
signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
<-quit
log.Println("Shutting down server...")

// 给服务一个超时时间来完成当前请求
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
defer cancel()
if err := srv.Shutdown(ctx); err != nil {
    log.Fatal("Server forced to shutdown:", err)
}
log.Println("Server exiting")
```



**7. Gin 的 `c.JSON()` 和 `c.String()` 等渲染方法在底层做了什么？**

**参考回答**：
这些方法最终都会调用 `c.Render`。`c.JSON()` 会：

1. 设置响应头的 `Content-Type` 为 `application/json; charset=utf-8`。
2. 使用 Go 标准库的 `json.Marshal()` 将你的结构体序列化为 JSON 字节数组。
3. 将字节数组写入响应体。

关键在于，Gin 在写入响应体后，**不会立即调用 `c.Next()`**，因为响应已经发送了。所以，在中间件中，如果你想修改响应，必须在调用 `c.Next()`**之前**进行。

## Django

### **一、核心概念与架构**

**1. 请解释一下 Django 的 MVT 架构，它与 MVC 有什么区别？**

**参考回答：**
Django 采用的是 **MVT（Model-View-Template）** 模式，它是 MVC 的一种变体，核心思想是分离关注点。

- **Model（模型）**：负责与数据库交互，定义数据结构。这完全对应 MVC 中的 Model。
- **View（视图）**：在 Django 中，这是**业务逻辑层**。它处理请求，从 Model 获取数据，然后将其传递给 Template。它相当于 MVC 中的 **Controller**。
- **Template（模板）**：负责**表现层**，即如何将数据渲染成 HTML。这相当于 MVC 中的 **View**。

**简单总结**：Django 的 MVT 中，`View` 干了 `Controller` 的活，而 `Template` 干了 `View` 的活。这种设计让业务逻辑和页面展示清晰分离。

------

### **二、模型与数据库层**

**2. 讲讲 Django ORM 的优势以及你常用的查询操作？**

**参考回答：**
Django ORM 的最大优势在于**抽象性**和**开发效率**。它让我们可以用 Python 代码来操作数据库，而无需编写原生 SQL，同时也通过 **QuerySet** 的惰性执行机制来优化性能。

**常用查询操作（可以结合你的测试平台举例）：**

```python
# 1. 基本查询
all_cases = TestCase.objects.all() # 获取全部
case = TestCase.objects.get(id=1) # 获取单个（唯一）

# 2. 过滤 (Filter)
high_priority_cases = TestCase.objects.filter(priority=1) # 等于
recent_cases = TestCase.objects.filter(create_time__gte=timezone.now() - timedelta(days=7)) # 大于等于

# 3. 关联查询 (ForeignKey)
# 假设 TestCase 属于一个 Project
cases_in_project_a = TestCase.objects.filter(project__name="Project A") # 双下划线跨表

# 4. 聚合与注解 (Aggregation & Annotation)
from django.db.models import Count, Avg
# 统计每个项目的测试用例数量
project_stats = Project.objects.annotate(total_cases=Count('testcase'))
```



**关联经验**：在我做的测试平台中，我需要频繁使用 `filter` 来按项目、优先级、创建者等条件筛选测试用例，并使用 `annotate` 来生成统计报表，ORM 让这些操作变得非常直观。

**3. 什么是 QuerySet 的“惰性执行”？它有什么好处？**

**参考回答：**
“惰性执行”是指创建一个 QuerySet 并不会立即触发数据库查询。只有当你**真正需要数据**时（例如对 QuerySet 进行迭代、切片、序列化或调用 `len()`, `list()` 时），查询才会发生。

**好处**：

- **性能优化**：你可以在最后时刻之前，通过链式调用不断地给 QuerySet 添加过滤条件，Django 最终只会向数据库发送一条高效的 SQL。
- **避免不必要的查询**：比如，如果你只是想在模板中判断 `if queryset.exists()`，Django 会优化成一个 `SELECT 1 ... LIMIT 1` 查询，而不是取出所有数据。

------

### **三、视图与请求处理**

**4. Django 的 Class-Based Views (CBV) 和 Function-Based Views (FBV) 各有什么优缺点？你更喜欢用哪种？**

**参考回答：**
这是一个经典问题，没有绝对答案，考察的是你的经验和场景分析能力。

- **FBV（函数视图）**：
  - **优点**：简单、直观、易于理解，对于简单的逻辑非常直接。
  - **缺点**：当处理多种 HTTP 方法（GET/POST）或有复杂继承关系时，代码容易变得冗长，需要通过 `if request.method == ...` 来区分。
- **CBV（类视图）**：
  - **优点**：**代码复用性高**，通过继承和混入（Mixins）可以极大地减少重复代码。内置了 `get()`, `post()` 等方法来分离不同请求方法的逻辑，结构更清晰。
  - **缺点**：学习曲线稍陡，需要理解 `as_view()`, `dispatch()` 等机制，不够“透明”。

**我的偏好与理由**：

> 对于**简单的、一次性的** API 或页面，我会用 FBV，因为它足够快。但对于**具有标准 CRUD 操作**的功能，我强烈推荐使用 CBV。例如，在我的测试用例管理平台中，列表和详情页面对应 `ListView` 和 `DetailView`，创建和更新对应 `CreateView` 和 `UpdateView`。使用 CBV 和 Django 内置的 `LoginRequiredMixin`，我只需几行代码就能实现一个需要登录才能访问的、带分页的测试用例列表页面，这大大提升了开发效率。

------

### **四、中间件与安全**

**5. Django 中间件是什么？它的执行顺序是怎样的？请举一个你用过或写过的中间件例子。**

**参考回答：**
Django 中间件是一个轻量级的、底层的“插件”系统，用于在**全局范围**内修改 Django 的请求（request）或响应（response）。

**执行流程（洋葱模型）**：

1. **请求阶段**：从上到下依次执行每个中间件的 `process_request` 方法。
2. **视图阶段**：执行视图函数。
3. **响应阶段**：从下到上依次执行每个中间件的 `process_response` 方法。
4. **异常阶段**：如果在任何地方抛出异常，会从下到上执行 `process_exception` 方法。

**例子**：

- **内置中间件**：我经常使用 `django.middleware.csrf.CsrfViewMiddleware` 来防护 CSRF 攻击，以及 `django.contrib.sessions.middleware.SessionMiddleware` 来管理用户会话。
- **自定义中间件**：我写过类似的**日志中间件**，在 `process_request` 中记录请求到达时间，在 `process_response` 中计算总耗时并记录。这和我在 Gin 框架里做的中间件思想是相通的。

**6. Django 提供了哪些内置的安全防护机制？**

**参考回答（这是 Django 的强项，务必掌握）**：
Django 在安全方面考虑得非常周全：

- **CSRF 保护**：通过中间件和模板标签 `{% csrf_token %}` 自动防护跨站请求伪造攻击。
- **SQL 注入防护**：ORM 使用参数化查询，从根本上避免了大部分 SQL 注入风险。
- **XSS 防护**：模板系统默认会自动转义 HTML 特殊字符，防止恶意脚本执行。
- **点击劫持防护**：可以通过 `X-Frame-Options` 中间件来防止。
- **安全的密码管理**：使用 PBKDF2 等强哈希算法存储密码，而不是明文。

------

### **五、高级特性与部署**

**7. Django 的 `settings.py` 配置有什么最佳实践？如何管理不同环境的配置？**

**参考回答：**
将敏感信息（如 SECRET_KEY，数据库密码）硬编码在 `settings.py` 中是极不安全的。

**最佳实践是使用环境变量**：

```python
# settings.py
import os
SECRET_KEY = os.environ.get('SECRET_KEY')
DEBUG = os.environ.get('DEBUG', 'False').lower() == 'true'

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.environ.get('DB_NAME'),
        'USER': os.environ.get('DB_USER'),
        'PASSWORD': os.environ.get('DB_PASSWORD'),
        'HOST': os.environ.get('DB_HOST', 'localhost'),
        'PORT': os.environ.get('DB_PORT', '5432'),
    }
}
```

这样，在开发、测试、生产环境中，我们可以通过不同的环境变量文件或服务器配置来注入不同的值，保证安全性和灵活性。

**8. 什么是 Django Signals？它的使用场景和注意事项是什么？**

**参考回答：**
Django Signals 实现了**观察者模式**，用于在框架执行某些动作（如保存模型 `post_save`，删除模型 `post_delete`）时，发送通知，允许其他部分的代码“订阅”这些通知并做出响应。

**使用场景**：

- 用户注册成功后，自动发送欢迎邮件。
- 创建一个对象后，自动在日志系统中记录一条信息。

**注意事项**：

- **避免滥用**：Signals 的调用是隐式的，会使代码逻辑变得不清晰，难以追踪。如果逻辑可以直接在视图或模型方法中实现，那就不要用 Signals。
- **性能影响**：如果信号处理函数执行缓慢，会拖慢主请求流程。
- **循环导入**：在 `models.py` 中注册信号容易引起循环导入问题，最佳实践是在 `apps.py` 的 `ready()` 方法中导入和注册。

## FastApi

### **一、核心概念与优势**

**1. FastAPI 的主要特点和优势是什么？为什么要选择它而不是 Flask 或 Django？**

**参考回答：**
FastAPI 是一个现代、快速（高性能）的 Python Web 框架，用于构建 API。它的核心优势在于：

- **高性能**：基于 **Starlette**（用于 Web 操作）和 **Pydantic**（用于数据操作），性能与 NodeJS 和 Go 相当，是现有最快的 Python 框架之一。
- **快速开发**：开发功能的速度可以提高约 200% 至 300%，这得益于其直观的 API 和强大的编辑器支持。
- **类型提示**：深度集成 Python 类型提示，在代码编写阶段就能捕获许多错误。
- **自动交互式 API 文档**：自动生成 Swagger UI 和 ReDoc 文档，前端团队可以立即查看和测试 API。
- **基于标准**：完全基于（并兼容）开放的 API 标准，如 OpenAPI 和 JSON Schema。

**与 Flask/Django 的对比**：

- **vs Flask**：Flask 更微内核，需要组合很多扩展。FastAPI"开箱即用"，提供了数据验证、文档生成、依赖注入等现代化特性，性能也更高。
- **vs Django**：Django 是"全家桶"式框架，适合构建包含模板渲染的传统 Web 应用。FastAPI 更专注于构建高性能的 **API**，特别是微服务和前后端分离的架构。它更轻量，异步支持更原生。

**关联经验**：在我评估技术选型时，如果项目需求是构建一个高性能、要求有严格数据契约和清晰文档的 RESTful API 服务，我会优先考虑 FastAPI。它的类型提示和自动文档，对于我参与的测试平台这类需要与前端精确对接的项目来说，价值巨大。

------

### **二、数据验证与序列化**

**2. Pydantic 模型在 FastAPI 中起什么作用？请举例说明。**

**参考回答：**
Pydantic 是 FastAPI 的基石，它通过 Python 类型提示来进行：

1. **数据验证**：当数据无效时自动抛出清晰的错误。
2. **数据序列化/反序列化**：将 JSON 数据转换为 Python 对象，以及将 Python 对象转换为 JSON。
3. **设置管理**：可以通过模型来定义和验证配置。

**关联项目示例**：
假设在我的测试平台中，有一个创建测试用例的接口，我会这样定义 Pydantic 模型：

```python
from pydantic import BaseModel, constr
from typing import Optional
from enum import Enum

class PriorityEnum(int, Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3

class TestCaseCreate(BaseModel):
    name: constr(min_length=1, max_length=100)  # 带长度限制的字符串
    description: Optional[str] = None
    script_path: str
    priority: PriorityEnum = PriorityEnum.MEDIUM

# 在路径操作函数中使用
@app.post("/testcases/")
async def create_test_case(test_case: TestCaseCreate):
    # 此时 `test_case` 已经是一个验证通过的 TestCaseCreate 对象
    # 我们可以直接使用其属性，如 test_case.name, test_case.priority
    return {"message": f"Test case '{test_case.name}' created", "priority": test_case.priority}
```



FastAPI 会自动基于这个模型验证请求体，并生成对应的 API 文档。

------

### **三、依赖注入系统**

**3. FastAPI 的依赖注入系统是如何工作的？它解决了什么问题？**

**参考回答：**
FastAPI 拥有一个极其强大且易用的依赖注入系统。它的核心思想是声明某个函数或类的"依赖项"，框架会自动帮你解决（即注入）这些依赖。

它解决了以下问题：

- **代码复用**：将共享的逻辑（如认证、数据库会话获取）提取为依赖项，在多个路由中复用。
- **业务逻辑分离**：使路径操作函数专注于处理核心业务，而将诸如认证、权限检查等横切关注点交给依赖项处理。
- **易于测试**：可以轻松地用 Mock 对象替换依赖项，便于单元测试。

**关联项目示例**：
我可以创建一个获取当前用户的依赖项，用于需要身份认证的接口：

```python
from fastapi import Depends, HTTPException, Header
from . import auth_service  # 假设的认证服务模块

async def get_current_user(token: str = Header(..., alias="Authorization")):
    user = await auth_service.verify_token(token)
    if user is None:
        raise HTTPException(status_code=401, detail="Invalid token")
    return user

@app.get("/users/me")
async def read_user_me(current_user: dict = Depends(get_current_user)):
    # 只有认证成功的用户才能访问这个接口
    return {"user": current_user}

@app.post("/testcases/")
async def create_test_case(test_case: TestCaseCreate, current_user: dict = Depends(get_current_user)):
    # 创建测试用例也需要用户登录
    # ... 业务逻辑
    return {"message": "Created"}
```



这样，`get_current_user` 这个依赖项就被复用了，并且让路由函数非常干净。

------

### **四、异步支持**

**4. FastAPI 的异步支持是怎样的？什么情况下应该使用 `async def`？**

**参考回答：**
FastAPI 基于 **Starlette**，对异步提供了"一等公民"级别的支持。你可以使用 `async def` 来定义异步的路径操作函数。

使用 `async def` 的黄金法则是：

- **当你的函数内部有 `await` 调用时（即执行 I/O 密集型操作**），你必须使用 `async def`。例如：调用另一个异步 API、执行异步数据库操作、进行异步文件读写等。
- **如果你的函数内部没有 `await`（即主要是 CPU 密集型操作**），那么你应该使用普通的 `def`。因为 FastAPI 会在一个单独的线程池中运行它，避免阻塞事件循环。

**示例**：

```python
import asyncio

# I/O 密集型，使用 async
@app.get("/async-data")
async def read_async_data():
    # 模拟一个异步的网络请求
    await asyncio.sleep(1)
    return {"message": "Data from async call"}

# CPU 密集型，使用普通 def
@app.get("/compute")
def heavy_computation():
    # 模拟一个繁重的计算任务
    result = some_heavy_cpu_task()
    return {"result": result}
```



------

### **五、高级特性与实战**

**5. 如何为 FastAPI 应用添加自定义中间件？**

**参考回答：**
添加中间件与在 Starlette 中一样。中间件函数接收 `request`，调用一个 `call_next` 函数来继续处理请求，然后可以在返回前处理 `response`。

**关联项目示例**（与你做过的 Gin/DIango 中间件思想一致）：

```python
import time
from fastapi import Request

@app.middleware("http")
async def add_process_time_header(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request) # 1. 处理请求，得到响应
    process_time = time.time() - start_time # 2. 计算耗时
    response.headers["X-Process-Time"] = str(process_time) # 3. 添加自定义响应头
    return response
```



**6. FastAPI 自动生成的 API 文档路径是什么？它是如何工作的？**

**参考回答：**

- **Swagger UI**：`/docs`
- **ReDoc**：`/redoc`

它的工作原理是：FastAPI 在启动时，会根据你的**路径操作**、**Pydantic 模型**、**参数声明**等，自动生成一个符合 **OpenAPI** 规范的应用程序结构。Swagger UI 和 ReDoc 都是这个 OpenAPI 规范的可视化工具，它们通过读取这个规范来渲染出交互式文档。你代码中的类型提示和文档字符串（docstrings）都会被自动纳入这个文档中。

------

### **六、与其他技术结合**

**7. 如何在 FastAPI 中连接数据库（例如，使用 SQLAlchemy）？**

**参考回答：**
最佳实践是使用依赖注入来管理数据库会话（Session）的生命周期。

**关联项目示例**：

```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# 依赖项
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# 在路径操作中使用
@app.post("/testcases/")
def create_test_case(test_case: TestCaseCreate, db: Session = Depends(get_db)):
    # ... 使用 db 进行数据库操作
    db_test_case = DBTestCase(**test_case.dict())
    db.add(db_test_case)
    db.commit()
    db.refresh(db_test_case)
    return db_test_case
```

这个 `get_db` 依赖项确保了每个请求都会获得一个独立的数据库会话，并在请求处理完成后正确关闭它。

## 语言

### **1. Golang (你的核心优势)**

**常见问题：**

- Go 的并发模型是什么？Goroutine 和线程有什么区别？
- `Channel` 是什么？它有缓冲和无缓冲的区别是什么？
- Go 的 `defer` 语句是如何工作的？
- Go 的面向对象是怎样的？（没有 `class`）
- 值接收者和指针接收者的区别？

**如何回答（结合项目）：**

**问题：请谈谈 Goroutine 和 Channel，以及你在项目中的应用。**

> **参考回答：**
> Go 的并发模型是其核心优势。Goroutine 是轻量级的用户态线程，创建和销毁开销极小。Channel 则是 Goroutine 之间的通信机制，提倡 **“通过通信来共享内存”**，而不是“通过共享内存来通信”，这能更安全地处理并发。
>
> - **Goroutine vs 线程**：一个 OS 线程可以承载成千上万个 Goroutine。Goroutine 的调度由 Go 运行时负责，而不是操作系统，因此上下文切换更快。
> - **Channel**：无缓冲 Channel 提供强同步保证——发送和接收必须同时准备好。有缓冲 Channel 则类似一个队列，提供了异步处理的能力。
>
> **在我的分布式测试框架中**，我使用 **Goroutine** 来并发执行多个测试任务，这类似于我用 Python 的 `multiprocessing`，但更轻量、高效。同时，我使用 **有缓冲的 Channel** 作为任务队列，主 Goroutine 将测试任务发送到 Channel，多个工作 Goroutine 从 Channel 中接收并执行任务，完美地实现了生产者和消费者模式，高效且安全地协调了分布式测试任务。

------

### **2. Python (你的核心脚本/工具语言)**

**常见问题：**

- Python 的 GIL（全局解释器锁）是什么？它有什么影响？
- 列表（List）和元组（Tuple）的区别？
- 装饰器（Decorator）是什么？请举例说明。
- 深拷贝（Deep Copy）和浅拷贝（Shallow Copy）的区别？
- 如何管理 Python 的包和环境？（virtualenv, conda）

**如何回答（结合项目）：**

**问题：你怎么看 Python 的 GIL？它会影响你的项目吗？**

> **参考回答：**
> GIL 是 CPython 解释器中的一个互斥锁，它防止多个线程同时执行 Python 字节码。这导致在 **CPU 密集型多线程任务** 中，Python 无法真正利用多核优势。
>
> **但在我的项目中，我巧妙地绕过了 GIL 的限制：**
>
> - 对于 **I/O 密集型** 任务（如网络请求、文件读写），线程在等待 I/O 时会释放 GIL，所以多线程依然能有效提升效率。
> - 对于 **CPU 密集型** 任务（比如我的测试用例执行），我直接使用了 `multiprocessing` 模块来创建多个进程，每个进程有独立的 Python 解释器和内存空间，从而完全绕开了 GIL，实现了真正的并行计算。这正是我在 Jenkins 流水线中用来加速测试的核心手段。
> - 此外，对于计算密集的部分，也可以使用 Cython 或将关键部分用 C/C++ 实现扩展。
>
> 所以，理解 GIL 并选择合适的并发模型（多进程/多线程/异步）是高效使用 Python 的关键。

------

### **3. Java (体现 JVM 体系知识)**

**常见问题：**

- 谈谈 Java 中 `ArrayList` 和 `LinkedList` 的区别？
- 什么是 Java 的垃圾回收机制？
- `HashMap` 的工作原理是什么？
- 接口（Interface）和抽象类（Abstract Class）的区别？
- Spring 框架的核心是什么？（IoC, AOP）

**如何回答（定位为“熟悉”，可结合 Groovy/Jenkins）：**

**问题：Java 平台给你带来的最大优势是什么？**

> **参考回答：**
> 我认为 Java 平台最大的优势在于其 **成熟的生态系统和“一次编写，到处运行”的跨平台能力**。JVM 是一个极其优秀的运行时，它的 JIT（即时编译）技术和强大的垃圾回收器为应用提供了稳定的高性能基础。
>
> **虽然我近期的项目更多使用 Go 和 Python，但我对 JVM 体系非常熟悉**。例如：
>
> - 我使用 **Groovy**（一种基于 JVM 的动态语言）来编写 **Jenkins Pipeline 脚本**。这让我能直接利用庞大的 Java 类库，同时享受脚本语言的灵活性。
> - 我理解 Java 的核心特性，如面向对象、异常处理和多线程模型。这些知识让我在编写和维护 Jenkins 插件或复杂的 Pipeline 时游刃有余。
>
> 在我的测试框架中，Jenkins（Java 应用）负责整体的资源调度和流程控制，而我用 Groovy 编写的 Pipeline 则像胶水一样，将整个自动化流程灵活地串联起来。

------

### **4. Groovy (你的特色技能)**

**常见问题：**

- Groovy 和 Java 有什么区别/联系？
- 谈谈 Groovy 的闭包（Closure）和元编程（Metaprogramming）。
- 你为什么在项目中选择使用 Groovy？

**如何回答（这是你的王牌，必须答好）：**

**问题：你为什么在 Jenkins Pipeline 中选择 Groovy？**

> **参考回答：**
> 这是一个非常自然的技术选型。因为 **Jenkins 本身是用 Java 开发的，其 Pipeline 功能原生就选择 Groovy 作为 DSL（领域特定语言）**。
>
> **Groovy 相比 Java 的优势在这里体现得淋漓尽致：**
>
> - **无缝互操作**：我可以直接在 Pipeline 脚本中调用任何 Java 库，这对于整合公司现有的 Java 工具链至关重要。
> - **语法糖和动态性**：更简洁的语法（如可选的分号、括号）、强大的闭包、字符串插值等，让编写 Pipeline 脚本比写纯 Java 代码快得多，可读性更好。
> - **DSL 能力**：Groovy 非常适合用来创建流畅的、易于阅读的 DSL。Jenkins Pipeline 的 `stages`, `steps`, `parallel` 等语法本身就是一种 DSL，让运维和开发人员都能理解 CI/CD 流程。
>
> **在我的项目中**，我利用 Groovy 的灵活性，编写了复杂的、支持断点续跑的 Pipeline 脚本，并利用其元编程能力动态地生成和配置测试阶段，这是用纯 Java 实现会非常笨重的。

------

### **5. C/C++ (定位为“了解”，展示底层理解)**

**常见问题：**

- C++ 中 `new` 和 `malloc` 的区别？
- 什么是智能指针？它解决了什么问题？
- C 和 C++ 的主要区别是什么？
- 什么是内存泄漏？如何避免？
- 虚函数（Virtual Function）和虚表（vTable）是什么？

**如何回答（展示底层知识，而非细节）：**

**问题：你为什么认为 C/C++ 知识对后端开发工程师仍有价值？**

> **参考回答：**
> 尽管我目前的开发工作主要使用高级语言，但我认为了解 C/C++ 是至关重要的，因为它能帮助我理解计算机系统的底层工作原理。
>
> - **性能理解**：当我用 Go 或 Python 优化性能时，我理解其背后的代价。比如，我知道 Go 的 Goroutine 在底层是如何被调度的，Python 的对象模型会带来哪些内存开销。这种认知来自于对更接近硬件的语言的理解。
> - **技术栈基础**：很多现代技术的底层是用 C/C++ 构建的，比如 Docker（Go 写的，但依赖 Linux 内核的 C 实现）、Redis、Nginx、甚至 Python 解释器本身。了解 C/C++ 让我能更好地理解和使用这些工具。
> - **解决复杂问题**：当遇到必须极致性能的场景（如高频交易、游戏引擎）或需要直接操作硬件时，C/C++ 是不可替代的。虽然我目前不常写，但这种底层思维模式能帮助我在设计系统时做出更合理的架构决策。
>
> 例如，我在处理 GPU 测试时，虽然框架用 Python/Go，但底层的 GPU 驱动和 CUDA 库本身就是 C/C++ 的生态，理解它们有助于我更好地定位更深层的问题。

------

### **总结：如何应对“你为什么用语言A而不是语言B”**

> “在我的 **分布式测试框架** 中，**核心调度器** 对并发性能要求极高，所以我选择了 **Golang**，因为它的 Goroutine 和 Channel 原生支持高并发，编译部署也简单。至于 **CI/CD 流程编排**，由于 Jenkins 的原生支持，使用 **Groovy** 来编写 Pipeline 是最自然、最高效的选择。”

## 数据库

### **一、MySQL (关系型数据库代表)**

**常见问题：**

1. **MySQL的存储引擎InnoDB和MyISAM有什么区别？为什么现在默认使用InnoDB？**
2. **什么是事务？请解释ACID特性。**
3. **谈谈MySQL的索引原理？B+树为什么适合做数据库索引？**
4. **什么是脏读、幻读、不可重复读？MySQL的隔离级别有哪些？**
5. **如何进行SQL优化？EXPLAIN命令的关键字段怎么看？**

**如何回答（结合项目）：**

**问题：在你们项目中，MySQL主要承担什么角色？遇到过什么性能问题，如何解决的？**

> **参考回答：**
> 在我的测试用例管理平台中，MySQL 作为**核心业务数据存储**，负责存储测试用例、项目信息、用户权限等**结构化程度高、关系复杂**的数据。
>
> **为什么选择MySQL？**
>
> - **数据一致性要求高**：测试用例的创建、更新、删除需要满足事务的ACID特性。
> - **复杂查询**：需要支持多条件的联合查询，例如“查询项目A下优先级为高的所有测试用例”。
> - **成熟稳定**：生态完善，社区活跃，运维工具成熟。
>
> **性能优化实践：**
>
> - **索引优化**：我为经常作为查询条件的字段，如 `project_id`、`name`、`priority` 创建了联合索引。通过 `EXPLAIN` 命令分析慢查询，确保查询使用了最合适的索引，避免全表扫描。
> - **查询优化**：避免使用 `SELECT *`，只取需要的字段。对大数据量的分页查询，不使用 `LIMIT offset, size`（因为offset越大越慢），而是使用 `WHERE id > [上一页最大ID] LIMIT size` 的方式。
> - **架构层面**：考虑过对读写压力大的表进行**主从分离**，读请求走从库。

------

### **二、Redis (内存键值数据库/缓存)**

**常见问题：**

1. **Redis为什么这么快？**
2. **Redis有哪些数据结构？分别有什么应用场景？**
3. **Redis的持久化机制RDB和AOF有什么区别？如何选择？**
4. **什么是缓存穿透、缓存击穿、缓存雪崩？如何解决？**
5. **如何用Redis实现分布式锁？**

**如何回答（结合项目）：**

**问题：你在简历中提到用Redis实现分布式任务调度，能详细说说吗？**

> **参考回答：**
> 当然。这是我**Jenkins分布式测试框架**的核心组件之一。我使用Redis主要作为**分布式任务队列**和**状态缓存**。
>
> **1. 任务队列（使用List结构）：**
>
> - 主节点（Master）将解析出的测试任务单元，作为JSON字符串 `LPUSH` 到一个名为 `pending_test_queue` 的List中。
> - 多个工作节点（Worker）通过 `BRPOP` 命令阻塞地从队列中争抢任务。`BRPOP` 是原子性的，保证了同一个任务不会被多个Worker重复获取。
>
> **2. 状态缓存与协调（使用Hash结构）：**
>
> - 我创建了一个 `task_status` 的Hash，以任务ID为field，存储任务的状态（`pending`, `running`, `success`, `failed`）、开始时间、执行节点等信息。
> - Worker抢到任务后，会立即在 `task_status` 中更新该任务状态为 `running`，并记录心跳时间。
> - Master节点通过轮询这个Hash，可以实时监控所有任务的执行状态和健康度。
>
> **为什么选择Redis？**
>
> - **高性能**：内存操作，单线程无锁设计，完全满足高并发任务调度的性能要求。
> - **丰富的数据结构**：List和Hash完美匹配了队列和状态存储的需求。
> - **原子操作**：`BRPOP`、`HSETNX` 等命令保证了分布式环境下的数据一致性。
> - **支持过期时间**：我可以为任务设置TTL，防止任务因Worker崩溃而永远处于运行状态。

------

### **三、MongoDB (文档型数据库)**

**常见问题：**

1. **MongoDB和传统关系型数据库（如MySQL）的核心区别是什么？**
2. **什么是副本集（Replica Set）和分片（Sharding）？**
3. **MongoDB的索引机制是怎样的？**
4. **MongoDB适合哪些应用场景？**
5. **谈谈MongoDB的写关注（Write Concern）和读偏好（Read Preference）。**

**如何回答（结合项目）：**

**问题：什么情况下你会选择MongoDB而不是MySQL？**

> **参考回答：**
> 技术选型的核心是**基于业务场景和数据模型**。
>
> **我会选择MongoDB当遇到以下情况时：**
>
> - **数据结构不固定，频繁变化**：例如，我负责的测试平台需要记录**多种不同类型的测试结果**（功能测试、性能测试、安全扫描），每种测试的指标和结构差异很大。如果用MySQL，需要设计一个复杂的、包含大量可空字段的表，或者频繁的ALTER TABLE，这很难维护。而MongoDB的**无模式（Schema-less）** 设计允许我轻松地将不同结构的测试结果直接存储为一个文档。
> - **读写吞吐量要求高，且数据模型是文档型**：例如，需要存储和查询整个**测试用例的配置JSON**，MongoDB可以直接存储和查询，无需像MySQL那样拆分成多表再JOIN。
> - **需要强大的水平扩展能力**：当数据量巨大时，MongoDB的**分片（Sharding）** 机制可以轻松地将数据分布到多个节点上，这是MySQL需要借助第三方中间件才能较好实现的功能。
>
> **在我的项目中**，虽然核心的测试用例元数据用了MySQL，但对于**测试执行过程中产生的详细日志、性能趋势图数据**这类半结构化、海量的数据，MongoDB是一个非常好的选择。它的副本集也提供了自动故障转移，保证了高可用性。

------

### **四、综合与对比**

**常见问题：**

1. **如果让你设计一个电商系统，你会如何在这三种数据库中进行数据存储的规划？**
2. **Redis除了做缓存，你还知道哪些高级用法？**

**如何回答（展示架构能力）：**

**问题：请对比一下MySQL、Redis和MongoDB。**

> **参考回答：**
> 我把它们看作一个系统架构中的不同“角色”：
>
> - **MySQL是系统的“会计”**：它严谨、可靠，负责存储最核心、关系最复杂、对一致性要求最高的数据。比如用户账户、订单、商品SKU。它的强项在于**事务支持和复杂的关联查询**。
> - **Redis是系统的“闪电侠”**：它速度极快，但数据在内存中，通常作为**缓存、消息队列和高速暂存区**。比如缓存热点商品信息、存储用户Session、实现秒杀系统的库存扣减。它的强项在于**性能和丰富的数据结构**。
> - **MongoDB是系统的“博物学家”**：它灵活、扩展性强，适合存储**文档型、半结构化或海量日志类数据**。比如商品详情页的JSON数据、APP的行为日志、物联网设备的传感数据。它的强项在于**灵活的模式和水平扩展能力**。
>
> **在我的测试框架中**，这个分工就很明确：
>
> - **MySQL**：存测试用例、项目的元数据（严谨，需要事务）。
> - **Redis**：做任务队列和实时状态缓存（高速，需要并发控制）。
> - **MongoDB**（可选方案）：存每次测试运行的详细日志和性能数据（灵活，数据量大）。

## Shell

### 文件操作

### 重点面试题目

1. **如何递归查找并删除7天前的.log文件？**
2. **批量重命名目录下所有.txt文件为.bak？**
3. **如何统计文件中每个单词的出现频率？**
4. **查找并替换文件中的特定文本内容？**
5. **如何比较两个文件的差异并生成补丁？**

#### 1. 文件查找与操作

bash

```bash
# find命令高级用法
find /path -name "*.log" -mtime +7 -exec rm {} \;
find /var/log -type f -size +1G -exec gzip {} \;

# xargs配合使用
find . -name "*.tmp" | xargs rm
```

#### 2. 文本处理三剑客

```bash
# grep文本搜索
grep -r "error" /var/log/
grep -c "pattern" file.txt
grep -v "exclude" file.txt  # 反向匹配

# sed流编辑器
sed 's/old/new/g' file.txt
sed -i.bak '/pattern/d' file.txt  # 删除匹配行并备份
sed -n '10,20p' file.txt  # 打印10-20行

# awk文本分析
awk '{print $1}' file.txt  # 打印第一列
awk -F: '{print $1, $3}' /etc/passwd  # 指定分隔符
awk '$3 > 1000 {print $0}' file.txt  # 条件过滤
```

#### 3. 文件比较与校验

```bash
# 文件比较
diff file1 file2
diff -u file1 file2 > patchfile  # 生成补丁

# 文件校验
md5sum file.txt
sha256sum file.txt
```

#### 一、find命令 - 文件查找

##### 1. 基础语法

```bash
find [路径] [选项] [操作]
```

##### 2. 由浅入深示例

###### 基础查找

```bash
# 在当前目录查找所有.txt文件
find . -name "*.txt"

# 在指定目录查找
find /home -name "*.log"

-name 条件本身没有文件类型限制，它会匹配：
普通文件 (.txt)
目录 (名为 notes.txt 的文件夹)
符号链接 (指向 .txt 文件的链接)
等等所有类型的文件

master@ubuntu241:~/shelldemo$ find . -name "*.txt"
./a.txt
./notes.txt
master@ubuntu241:~/shelldemo$ find . -type f -name "*.txt"
./a.txt

# 按类型查找
find . -type f          # 普通文件
find . -type d          # 目录
find . -type l          # 符号链接
```

###### 时间相关查找

```bash
# 按修改时间查找
find . -mtime -1        # 1天内修改的文件
find . -mtime +7        # 7天前修改的文件
find . -mmin -30        # 30分钟内修改的文件

# 按访问时间查找
find . -atime -1        # 1天内访问的文件
```

###### 大小相关查找

```bash
# 按文件大小查找
find . -size +1M        # 大于1MB的文件
find . -size -100k      # 小于100KB的文件
find . -size 0          # 空文件
```

###### 权限相关查找

```bash
# 按权限查找
find . -perm 644        # 权限为644的文件
find . -perm /u=x       # 用户有执行权限的文件
```

###### 组合条件查找

```bash
# 多条件组合
find . -name "*.log" -mtime +7 -size +10M
find /var -type f -name "*.log" -mtime +30

# 逻辑操作
find . -name "*.txt" -o -name "*.log"   # OR操作
find . ! -name "*.tmp"                  # NOT操作
```

###### 执行操作

```bash
# 查找并删除
find . -name "*.tmp" -delete
find . -name "*.bak" -exec rm {} \;

第一条命令：从当前目录（.）开始递归查找，找到所有以 .tmp 结尾的文件，并直接删除它们。-delete 是 find 命令的一个操作，它会删除找到的文件。

第二条命令：查找所有以 .bak 结尾的文件，并对每个找到的文件执行 rm 命令。-exec 是 find 命令的一个选项，它允许对找到的每个文件执行指定的命令。这里的 rm {} 中，{} 是一个占位符，会被替换为当前找到的文件名。\; 表示命令的结束，注意前面有一个空格，并且分号需要转义（或者可以用 ';' 或 ";"，但通常用转义的分号）。

# 查找并复制
find . -name "*.conf" -exec cp {} /backup/ \;
这条命令从当前目录开始递归查找所有以 .conf 结尾的文件，并对每个文件执行 cp 命令，将文件复制到 /backup/ 目录中。同样，{} 会被替换为找到的每个文件的路径。

# 查找并统计信息
find . -name "*.java" -exec wc -l {} \; | tail -1
查找所有 .java 文件
对每个文件执行 wc -l（统计行数）
| tail -1：只显示最后一行（通常是总行数统计） 某一个文件

find . -name "*.java" -exec wc -l {} +
50 ./Main.java
30 ./utils/Helper.java
20 ./test/Test.java
100 总行数
```

#### 二、grep命令 - 文本搜索

##### 1. 基础语法

```bash
grep [选项] "模式" [文件]
```

##### 2. 由浅入深示例

###### 基础搜索

```bash
# 在文件中搜索字符串
grep "error" logfile.txt
grep "success" /var/log/system.log

# 在多个文件中搜索
grep "pattern" file1.txt file2.txt
grep "error" *.log
```

###### 选项使用

```bash
# 忽略大小写
grep -i "error" logfile.txt

# 显示行号
grep -n "pattern" file.txt

# 显示匹配次数
grep -c "error" logfile.txt

# 反向匹配（不包含模式的行）
grep -v "success" logfile.txt

# 只显示匹配的文件名
grep -l "error" *.log
```

###### 递归搜索

```bash
# 递归搜索目录
grep -r "TODO" /project/src/

# 递归搜索，显示文件名和行号
grep -rn "function" .

# 递归搜索，忽略二进制文件
grep -rI "config" /etc/
```

###### 正则表达式

```bash
# 基本正则
grep "^start" file.txt          # 以start开头的行
grep "end$" file.txt            # 以end结尾的行
grep "^[A-Z]" file.txt          # 以大写字母开头的行

# 扩展正则（需要 -E）
grep -E "(error|warning)" logfile.txt
grep -E "[0-9]{3}-[0-9]{4}" file.txt  # 匹配电话号码格式
```

###### 上下文显示

```bash
# 显示匹配行及前后行
grep -A 2 "error" logfile.txt    # 后2行
grep -B 2 "error" logfile.txt    # 前2行
grep -C 2 "error" logfile.txt    # 前后各2行
```

#### 三、sed命令 - 流编辑器

##### 1. 基础语法

```bash
sed [选项] '命令' [文件]
```

##### 2. 由浅入深示例

###### 基础替换

```bash
# 替换每行第一个匹配
sed 's/old/new/' file.txt

# 替换所有匹配
sed 's/old/new/g' file.txt

# 替换指定行的匹配
sed '2s/old/new/' file.txt        # 只替换第2行
sed '2,5s/old/new/g' file.txt     # 替换2-5行
```

###### 行操作

```bash
# 删除行
sed '3d' file.txt                 # 删除第3行
sed '2,5d' file.txt               # 删除2-5行
sed '/pattern/d' file.txt         # 删除匹配行

# 插入和追加
sed '2i\插入的内容' file.txt       # 在第2行前插入
sed '2a\追加的内容' file.txt       # 在第2行后追加
```

###### 多命令操作 

```bash
# 多个命令用分号分隔
sed 's/old/new/g; s/foo/bar/g' file.txt

# 或使用 -e 选项
sed -e 's/old/new/' -e 's/foo/bar/' file.txt
```

###### 文件操作

```bash
# 原地修改（小心使用）
sed -i 's/old/new/g' file.txt

# 原地修改并备份原文件
sed -i.bak 's/old/new/g' file.txt

# 只打印修改的行
sed -n 's/old/new/p' file.txt
```

###### 高级用法

```bash
# 使用正则分组
echo "hello world" | sed 's/\(hello\) \(world\)/\2 \1/'

# 条件替换
sed '/error/s/old/new/g' file.txt  # 只在包含error的行中替换

# 范围操作
sed '/start/,/end/d' file.txt      # 删除从start到end的所有行
```



#### 四、awk命令 - 文本处理语言

##### 1. 基础语法

```bash
awk '模式 {动作}' [文件]
```

##### 2. 由浅入深示例

###### 基础字段处理

```bash
# 打印指定字段
awk '{print $1}' file.txt          # 打印第一列
awk '{print $1, $3}' file.txt      # 打印第1和第3列

# 指定分隔符
awk -F: '{print $1, $3}' /etc/passwd
awk -F'[ :]' '{print $1, $2}' file.txt  # 多个分隔符
```

###### 内置变量

```bash
# 常用内置变量
awk '{print NR, $0}' file.txt      # NR: 行号，$0: 整行
awk '{print NF, $NF}' file.txt     # NF: 字段数，$NF: 最后一个字段

# 打印文件名和行号
awk '{print FILENAME, NR, $0}' file.txt
```

###### 条件处理

```bash
# 条件判断
awk '$3 > 1000 {print $0}' file.txt
awk '/error/ {print $0}' file.txt
awk 'NF == 3 {print $0}' file.txt  # 正好3个字段的行

# 多条件
awk '$1 == "admin" && $3 > 1000 {print $0}' file.txt
```

###### 计算和统计

```bash
# 求和
awk '{sum += $1} END {print sum}' file.txt

# 统计行数
awk 'END {print NR}' file.txt

# 分组统计
awk '{count[$1]++} END {for (item in count) print item, count[item]}' file.txt
```

###### BEGIN和END块

```bash
# 添加表头
awk 'BEGIN {print "Name\tScore"} {print $1, $2} END {print "Total lines:", NR}' file.txt

# 计算平均值
awk '{sum += $1} END {print "Average:", sum/NR}' file.txt
```

#### 五、diff命令 - 文件比较

##### 1. 基础语法

```bash
diff [选项] 文件1 文件2
```

##### 2. 由浅入深示例

###### 基础比较

```bash
# 简单比较
diff file1.txt file2.txt

# 并排显示
diff -y file1.txt file2.txt

# 统一格式（适合生成补丁）
diff -u file1.txt file2.txt
```

###### 目录比较

```bash
# 比较目录
diff -r dir1 dir2

# 只显示不同的文件名
diff -rq dir1 dir2

# 忽略某些文件
diff -r --exclude="*.tmp" dir1 dir2
```

###### 生成和应用补丁

```bash
# 生成补丁文件
diff -u old.txt new.txt > patchfile.patch

# 应用补丁
patch old.txt < patchfile.patch

# 撤销补丁
patch -R old.txt < patchfile.patch
```

#### 六、重点面试题目命令详解

##### 1. 递归查找并删除7天前的.log文件

```bash
# 方法1：使用-exec
find /path -name "*.log" -mtime +7 -exec rm {} \;

# 方法2：使用-delete
find /path -name "*.log" -mtime +7 -delete

# 方法3：安全版本（先查看再删除）
find /path -name "*.log" -mtime +7 -ls
find /path -name "*.log" -mtime +7 -ok rm {} \;  # 交互式确认
```

##### 2. 批量重命名目录下所有.txt文件为.bak

```bash
# 方法1：使用rename命令
rename 's/\.txt$/.bak/' *.txt

# 方法2：使用循环和mv
for file in *.txt; do
    mv "$file" "${file%.txt}.bak"
done

# 方法3：使用find和-exec
find . -name "*.txt" -exec sh -c 'mv "$1" "${1%.txt}.bak"' _ {} \;
```

##### 3. 统计文件中每个单词的出现频率

```bash
# 方法1：使用tr、sort、uniq组合
tr -cs '[:alnum:]' '\n' < file.txt | sort | uniq -c | sort -nr

# 方法2：使用awk
awk '{
    for(i=1; i<=NF; i++) {
        word = tolower($i)
        gsub(/[^a-z0-9]/, "", word)
        if(word != "") count[word]++
    }
} 
END {
    for(word in count) print count[word], word
}' file.txt | sort -nr
```

##### 4. 查找并替换文件中的特定文本内容

```bash
# 方法1：使用sed（单个文件）
sed -i 's/old_text/new_text/g' file.txt

# 方法2：使用sed（多个文件）
sed -i 's/old_text/new_text/g' *.txt

# 方法3：使用perl（支持更复杂的正则）
perl -pi -e 's/old_text/new_text/g' file.txt

# 方法4：递归替换目录中的所有文件
find . -name "*.txt" -exec sed -i 's/old_text/new_text/g' {} \;
```

##### 5. 比较两个文件的差异并生成补丁

```bash
# 生成统一格式的差异
diff -u original.txt modified.txt > changes.patch

# 生成上下文格式的差异
diff -c original.txt modified.txt > changes.patch

# 比较二进制文件
diff -q file1.bin file2.bin

# 应用补丁
patch original.txt < changes.patch

# 检查补丁是否可以应用
patch --dry-run original.txt < changes.patch
```









